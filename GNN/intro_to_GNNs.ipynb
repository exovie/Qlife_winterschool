{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2361f4a6-2cc4-4347-aa21-f557e606bf6f",
      "metadata": {
        "id": "2361f4a6-2cc4-4347-aa21-f557e606bf6f"
      },
      "source": [
        "# Intro to Graph Neural Networks (GNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2389f5ed",
      "metadata": {
        "id": "2389f5ed"
      },
      "source": [
        "The goal of this notebook is to give you an idea how GNNs work in practice. To this end, a prototypical molecular graph will be constructed, after which a full GNN will be constructed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179733c6",
      "metadata": {
        "id": "179733c6"
      },
      "source": [
        "### Relevant packages: Pytorch Geometric (PyG)\n",
        "PyG is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data. You can also browse its [documentation](https://pytorch-geometric.readthedocs.io/en/latest/) for additional details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519f98ff",
      "metadata": {
        "id": "519f98ff"
      },
      "outputs": [],
      "source": [
        "# Install all libraries\n",
        "# CoLab has already preinstalled Pytorch for you\n",
        "! pip install pytorch-lightning wandb rdkit ogb\n",
        "# install PyG\n",
        "! pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d19b18b9",
      "metadata": {
        "id": "d19b18b9"
      },
      "source": [
        "Set a random seed to ensure repeatability of experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55c1555",
      "metadata": {
        "id": "a55c1555"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Random Seeds and Reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0465b86",
      "metadata": {
        "id": "a0465b86"
      },
      "source": [
        "### Molecular graph\n",
        "A [molecular graph](https://en.wikipedia.org/wiki/Molecular_graph) is a labeled graph whose nodes correspond to the atoms of the compound and edges correspond to chemical bonds. It also has node features (**atom features**), edge features (**bond features**) and graph labels (chemical properties of a molecule). Here, we demonstrate a simple example of building a molecular graph (undirected). Note that we do not consider hydrogen atoms as nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bd3c57",
      "metadata": {
        "id": "30bd3c57"
      },
      "outputs": [],
      "source": [
        "from rdkit.Chem import MolFromSmiles\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "IPythonConsole.ipython_useSVG = True  # < use SVGs instead of PNGs\n",
        "IPythonConsole.drawOptions.addAtomIndices = True  # adding indices for atoms\n",
        "IPythonConsole.drawOptions.addBondIndices = False  # not adding indices for bonds\n",
        "IPythonConsole.molSize = 200, 200\n",
        "\n",
        "# N,N-dimethylformamide (DMF)\n",
        "dmf_smiles = 'CN(C)C=O'\n",
        "mol = MolFromSmiles(dmf_smiles)\n",
        "# show molecular graph of DMF, atom indices = node indices\n",
        "mol"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdcba6a2",
      "metadata": {
        "id": "fdcba6a2"
      },
      "source": [
        "### Atom features\n",
        "\n",
        "| feature | description |\n",
        "| ---- | ----  |\n",
        "| atom type  | atomic number |\n",
        "| degree  | number of directly-bonded neighbor atoms, including H atoms |\n",
        "| formal charge | integer electronic charge assigned to atom |\n",
        "| hybridization | sp, sp2, sp3, sp3d, or sp3d2 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37cab5a2",
      "metadata": {
        "id": "37cab5a2"
      },
      "outputs": [],
      "source": [
        "ATOM_FEATURES = {\n",
        "    'atom_type' : [1, 6, 7, 8, 9],  # elements: H, C, N, O, F\n",
        "    'degree' : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'misc'],\n",
        "    'formal_charge' : [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 'misc'],\n",
        "    'hybridization' : [\n",
        "        'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'misc'\n",
        "        ],\n",
        "}\n",
        "\n",
        "def get_atom_fv(atom):\n",
        "    \"\"\"\n",
        "    Converts rdkit atom object to feature list of indices\n",
        "    :param atom: rdkit atom object\n",
        "    :return: list\n",
        "    \"\"\"\n",
        "    atom_fv = [\n",
        "        ATOM_FEATURES['atom_type'].index(atom.GetAtomicNum()),\n",
        "        ATOM_FEATURES['degree'].index(atom.GetTotalDegree()),\n",
        "        ATOM_FEATURES['formal_charge'].index(atom.GetFormalCharge()),\n",
        "        ATOM_FEATURES['hybridization'].index(str(atom.GetHybridization())),\n",
        "    ]\n",
        "    return atom_fv\n",
        "\n",
        "atom_fvs = [get_atom_fv(atom) for atom in mol.GetAtoms()]\n",
        "atom_fvs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a4906b",
      "metadata": {
        "id": "12a4906b"
      },
      "source": [
        "### Bond features\n",
        "\n",
        "| feature | description |\n",
        "| ---- | ----  |\n",
        "| bond type  | single, double, triple, or aromatic |\n",
        "| stereo | none, any, E/Z or cis/trans |\n",
        "| conjugated  | whether the bond is conjugated |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03427568",
      "metadata": {
        "id": "03427568"
      },
      "outputs": [],
      "source": [
        "# Show indices of bonds\n",
        "IPythonConsole.drawOptions.addAtomIndices = False  # not adding indices for atoms\n",
        "IPythonConsole.drawOptions.addBondIndices = True  # adding indices for bonds\n",
        "mol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7f2f28",
      "metadata": {
        "id": "3f7f2f28"
      },
      "outputs": [],
      "source": [
        "BOND_FEATURES = {\n",
        "    'bond_type' : [\n",
        "        'SINGLE',\n",
        "        'DOUBLE',\n",
        "        'TRIPLE',\n",
        "        'AROMATIC',\n",
        "        'misc'\n",
        "    ],\n",
        "    'stereo': [\n",
        "        'STEREONONE',\n",
        "        'STEREOZ',\n",
        "        'STEREOE',\n",
        "        'STEREOCIS',\n",
        "        'STEREOTRANS',\n",
        "        'STEREOANY',\n",
        "    ],\n",
        "    'conjugated': [False, True],\n",
        "}\n",
        "\n",
        "def get_bond_fv(bond):\n",
        "    \"\"\"\n",
        "    Converts rdkit bond object to feature list of indices\n",
        "    :param bond: rdkit bond object\n",
        "    :return: list\n",
        "    \"\"\"\n",
        "    bond_fv = [\n",
        "        BOND_FEATURES['bond_type'].index(str(bond.GetBondType())),\n",
        "        BOND_FEATURES['stereo'].index(str(bond.GetStereo())),\n",
        "        BOND_FEATURES['conjugated'].index(bond.GetIsConjugated()),\n",
        "    ]\n",
        "    return bond_fv\n",
        "\n",
        "bond_fvs = [get_bond_fv(bond) for bond in mol.GetBonds()]\n",
        "bond_fvs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a42b4193",
      "metadata": {
        "id": "a42b4193"
      },
      "source": [
        "### Edge index\n",
        "In many cases, a list of paired node indices are used to describe edges rather than adjacency matrix. Here we use paired node indices (`edge_index`) with shape (2, num_edges) to define the edges in a graph.\n",
        "\n",
        "$$\n",
        "\\mathbf{E} = \\begin{bmatrix}\n",
        "    ..., & i, & ..., & j, & ... \\\\\n",
        "    ..., & j, & ..., & i, & ...\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "So, from the paired node indices list, we can conclude that there has an edge between node $i$ and node $j$ (undirected graph).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4291b9d",
      "metadata": {
        "id": "b4291b9d"
      },
      "outputs": [],
      "source": [
        "edge_index0, edge_index1 = [], []\n",
        "\n",
        "for bond in mol.GetBonds():\n",
        "    i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "    edge_index0 += [i, j]\n",
        "    edge_index1 += [j, i]\n",
        "\n",
        "edge_index = [edge_index0, edge_index1]\n",
        "edge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbf2dbb",
      "metadata": {
        "id": "8cbf2dbb"
      },
      "source": [
        "### Molecular graph data\n",
        "\n",
        "We set the density of DMF(0.944 $g/cm^3$) as the graph feature (label). Here we use [Data](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) class in `PyG` to create a graph data for DMF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac3538d",
      "metadata": {
        "id": "bac3538d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# convert our data to tensors, which are used for model training\n",
        "x = torch.tensor(atom_fvs, dtype=torch.float)\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "edge_attr = torch.tensor(bond_fvs, dtype=torch.float)\n",
        "y = torch.tensor([0.944], dtype=torch.float)\n",
        "\n",
        "dmf_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "dmf_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b4e523",
      "metadata": {
        "id": "37b4e523"
      },
      "source": [
        "## Graph Neural Network\n",
        "\n",
        "A [graph neural network (GNN)](https://en.wikipedia.org/wiki/Graph_neural_network) is a class of artificial neural networks for processing data that can be represented as graphs. GNNs rely on [message passing methods](https://arxiv.org/abs/1704.01212), which means that nodes exchange information with the neighbors, and send \"messages\" to each other. Generally, GNNs operate in two phases: a **message passing** phase, which transmits information across the molecule to build a neural representation of the molecule, and a **readout** phase, which uses the final representation of the molecule to make predictions about the properties of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de73f99",
      "metadata": {
        "id": "8de73f99"
      },
      "source": [
        "Here, we will define a GNN model using message passing neural network (MPNN) according to paper [\"Neural Message Passing for Quantum Chemistry\"](https://arxiv.org/abs/1704.01212). We just use [NNConv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.NNConv.html#torch_geometric.nn.conv.NNConv) class to create message passing layers of our models (the various steps outlined in the lecture, i.e., 'send messages' + 'message aggregation' + 'node update' all happen under the hood inside this class). The [torch_geometric.nn](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html) module of PyG contains many different types of layers for message passing and readout, which can help us define GNN models more conveniently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67d234a",
      "metadata": {
        "id": "f67d234a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import GRU\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import NNConv, MLP, global_add_pool\n",
        "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
        "\n",
        "\n",
        "class MPNN(pl.LightningModule):\n",
        "    def __init__(self, hidden_dim, out_dim,\n",
        "                 train_data, valid_data, test_data,\n",
        "                 std, batch_size=32, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.std = std  # std of data's target\n",
        "        self.train_data = train_data\n",
        "        self.valid_data = valid_data\n",
        "        self.test_data = test_data\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        # Initial layers\n",
        "        self.atom_emb = AtomEncoder(emb_dim=hidden_dim)\n",
        "        self.bond_emb = BondEncoder(emb_dim=hidden_dim)\n",
        "        # Message passing layers\n",
        "        nn = MLP([hidden_dim, hidden_dim*2, hidden_dim*hidden_dim])\n",
        "        self.conv = NNConv(hidden_dim, hidden_dim, nn, aggr='mean')\n",
        "        self.gru = GRU(hidden_dim, hidden_dim)\n",
        "        # Readout layers\n",
        "        self.mlp = MLP([hidden_dim, int(hidden_dim/2), out_dim])\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "\n",
        "        # Initialization\n",
        "        x = self.atom_emb(data.x)\n",
        "        h = x.unsqueeze(0)\n",
        "        edge_attr = self.bond_emb(data.edge_attr)\n",
        "\n",
        "        # Message passing\n",
        "        for i in range(3):\n",
        "            m = F.relu(self.conv(x, data.edge_index, edge_attr))  # send message and aggregation\n",
        "            x, h = self.gru(m.unsqueeze(0), h)  # node update\n",
        "            x = x.squeeze(0)\n",
        "\n",
        "        # Readout\n",
        "        x = global_add_pool(x, data.batch)\n",
        "        x = self.mlp(x)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Here we define the train loop.\n",
        "        out = self.forward(batch, mode=\"train\")\n",
        "        loss = F.mse_loss(out, batch.y)\n",
        "        self.log(\"Train loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Define validation step. At the end of every epoch, this will be executed\n",
        "        out = self.forward(batch, mode=\"valid\")\n",
        "        loss = F.mse_loss(out * self.std, batch.y * self.std)  # report MSE\n",
        "        self.log(\"Valid MSE\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # What to do in test\n",
        "        out = self.forward(batch, mode=\"test\")\n",
        "        loss = F.mse_loss(out * self.std, batch.y * self.std)  # report MSE\n",
        "        self.log(\"Test MSE\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Here we configure the optimization algorithm.\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=self.lr\n",
        "        )\n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.valid_data, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04593bf6",
      "metadata": {
        "id": "04593bf6"
      },
      "source": [
        "Here, we can use [InMemoryDataset]() class in PyG to create the graph dataset of ESOL conveniently. You can also browse its [tutorial](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html) and [pre-defined dataset](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html) to learn about how to create graph datasets quickly by PyG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f7eeec9",
      "metadata": {
        "id": "9f7eeec9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset,\n",
        "    download_url,\n",
        ")\n",
        "from ogb.utils import smiles2graph\n",
        "\n",
        "\n",
        "class ESOLGraphData(InMemoryDataset):\n",
        "    \"\"\"The ESOL graph dataset using PyG\n",
        "    \"\"\"\n",
        "    # ESOL dataset download link\n",
        "    raw_url = 'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv'\n",
        "\n",
        "    def __init__(self, root, transform=None):\n",
        "        super().__init__(root, transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['delaney-processed.csv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        print('Downloading ESOL dataset...')\n",
        "        file_path = download_url(self.raw_url, self.raw_dir)\n",
        "\n",
        "    def process(self):\n",
        "        # load raw data from a csv file\n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        smiles = df['smiles'].values.tolist()\n",
        "        target = df['measured log solubility in mols per litre'].values.tolist()\n",
        "\n",
        "        # Convert SMILES into graph data\n",
        "        print('Converting SMILES strings into graphs...')\n",
        "        data_list = []\n",
        "        for i, smi in enumerate(tqdm(smiles)):\n",
        "\n",
        "            # get graph data from SMILES\n",
        "            graph = smiles2graph(smi)\n",
        "\n",
        "            # convert to tensor and pyg data\n",
        "            x = torch.tensor(graph['node_feat'], dtype=torch.long)\n",
        "            edge_index = torch.tensor(graph['edge_index'], dtype=torch.long)\n",
        "            edge_attr = torch.tensor(graph['edge_feat'], dtype=torch.long)\n",
        "            y = torch.tensor([target[i]], dtype=torch.float)\n",
        "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "            data_list.append(data)\n",
        "\n",
        "        # save data\n",
        "        torch.save(self.collate(data_list), self.processed_paths[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e88389",
      "metadata": {
        "id": "d3e88389"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "What is the SMILES string of the first molecule in the dataset? How many bonds are there in this molecule?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e36a47fb",
      "metadata": {
        "id": "e36a47fb",
        "outputId": "6c45e893-7d1d-4614-c396-debf4a0a3b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Data(x=[14991, 9], edge_index=[2, 30856], edge_attr=[30856, 3], y=[1128]), {'x': tensor([    0,    32,    47,  ..., 14967, 14972, 14991]), 'edge_index': tensor([    0,    68,   100,  ..., 30810, 30818, 30856]), 'edge_attr': tensor([    0,    68,   100,  ..., 30810, 30818, 30856]), 'y': tensor([   0,    1,    2,  ..., 1126, 1127, 1128])})\n"
          ]
        }
      ],
      "source": [
        "data = torch.load(\"/content/test/processed/data.pt\", weights_only=False)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f352ca3",
      "metadata": {
        "id": "9f352ca3"
      },
      "source": [
        "Create, normalize and split ESOL graph dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9c5d536d",
      "metadata": {
        "id": "9c5d536d"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple\n",
        "import numpy as np\n",
        "from torch_geometric.data.dataset import Dataset\n",
        "\n",
        "\n",
        "class RandomSplitter(object):\n",
        "    \"\"\"Class for doing random data splits.\"\"\"\n",
        "\n",
        "    def split(\n",
        "        self,\n",
        "        dataset: Dataset,\n",
        "        frac_train: float = 0.7,\n",
        "        frac_valid: float = 0.1,\n",
        "        frac_test: float = 0.2,\n",
        "        seed: Optional[int] = None,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Splits internal compounds randomly into train/validation/test.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: Dataset\n",
        "          Dataset to be split.\n",
        "        seed: int, optional (default None)\n",
        "          Random seed to use.\n",
        "        frac_train: float, optional (default 0.8)\n",
        "          The fraction of data to be used for the training split.\n",
        "        frac_valid: float, optional (default 0.1)\n",
        "          The fraction of data to be used for the validation split.\n",
        "        frac_test: float, optional (default 0.1)\n",
        "          The fraction of data to be used for the test split.\n",
        "        seed: int, optional (default None)\n",
        "          Random seed to use.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
        "          A tuple of train indices, valid indices, and test indices.\n",
        "          Each indices is a numpy array.\n",
        "        \"\"\"\n",
        "        np.testing.assert_almost_equal(frac_train + frac_valid + frac_test, 1.0)\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "        num_datapoints = len(dataset)\n",
        "        train_cutoff = int(frac_train * num_datapoints)\n",
        "        valid_cutoff = int((frac_train + frac_valid) * num_datapoints)\n",
        "        shuffled = np.random.permutation(range(num_datapoints))\n",
        "        return (\n",
        "            shuffled[:train_cutoff],\n",
        "            shuffled[train_cutoff:valid_cutoff],\n",
        "            shuffled[valid_cutoff:],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "fdb4e4f8-86b4-4edd-998d-897d5eb02d2c",
      "metadata": {
        "id": "fdb4e4f8-86b4-4edd-998d-897d5eb02d2c",
        "outputId": "1abd8b01-2c8c-4449-bdb1-7cd9eed14062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ESOL dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting SMILES strings into graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1128/1128 [00:00<00:00, 1657.08it/s]\n",
            "Done!\n",
            "/tmp/ipython-input-2786933328.py:5: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  mean = dataset.data.y.mean()\n",
            "/tmp/ipython-input-2786933328.py:6: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  std = dataset.data.y.std()\n",
            "/tmp/ipython-input-2786933328.py:7: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  dataset.data.y = (dataset.data.y - mean) / std\n"
          ]
        }
      ],
      "source": [
        "# create dataset\n",
        "dataset = ESOLGraphData('./esol_pyg').shuffle()\n",
        "\n",
        "# Normalize target to mean = 0 and std = 1.\n",
        "mean = dataset.data.y.mean()\n",
        "std = dataset.data.y.std()\n",
        "dataset.data.y = (dataset.data.y - mean) / std\n",
        "mean, std = mean.item(), std.item()\n",
        "\n",
        "# split data\n",
        "splitter = RandomSplitter()\n",
        "train_idx, valid_idx, test_idx = splitter.split(dataset, frac_train=0.7, frac_valid=0.1, frac_test=0.2)\n",
        "train_dataset = dataset[train_idx]\n",
        "valid_dataset = dataset[valid_idx]\n",
        "test_dataset = dataset[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9d8ad21d",
      "metadata": {
        "id": "9d8ad21d",
        "outputId": "0dcfbc76-650f-4a4a-f2dc-4441d014b0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cc36f62ae76f4dc38dab14555aa22c1c",
            "d837bdc3f6cf4ed087f81be81d2b03b3",
            "bff409cb008a4b95997bb5710d1dba7d",
            "25ce15a256fd4f5e9a7c49659161cd61"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName    \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType       \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ atom_emb ‚îÇ AtomEncoder ‚îÇ 11.1 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ bond_emb ‚îÇ BondEncoder ‚îÇ    832 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ conv     ‚îÇ NNConv      ‚îÇ  541 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ gru      ‚îÇ GRU         ‚îÇ 25.0 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m‚îÇ mlp      ‚îÇ MLP         ‚îÇ  2.2 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name     </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ atom_emb ‚îÇ AtomEncoder ‚îÇ 11.1 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ bond_emb ‚îÇ BondEncoder ‚îÇ    832 ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ conv     ‚îÇ NNConv      ‚îÇ  541 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ gru      ‚îÇ GRU         ‚îÇ 25.0 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>‚îÇ mlp      ‚îÇ MLP         ‚îÇ  2.2 K ‚îÇ train ‚îÇ     0 ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 580 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 580 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 36                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 580 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 580 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 36                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc36f62ae76f4dc38dab14555aa22c1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 424. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 424. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 412. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 412. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches \n",
              "(25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if\n",
              "you want to see logs for the training epoch.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches \n",
              "(25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if\n",
              "you want to see logs for the training epoch.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 462. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 462. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 230. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 230. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/lightning_logs/version_0/checkpoints/epoch=59-step=1500.ckpt\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at /content/lightning_logs/version_0/checkpoints/epoch=59-step=1500.ckpt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bff409cb008a4b95997bb5710d1dba7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 360. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 360. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 365. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 365. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 405. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 405. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 440. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 440. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 397. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 397. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 473. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 473. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 425. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 425. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 22. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` \n",
              "from an ambiguous collection. The batch size we found is 22. To avoid any miscalculations, use `self.log(..., \n",
              "batch_size=batch_size)`.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ\u001b[36m \u001b[0m\u001b[36m        Test MSE         \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.3911325931549072    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\">        Test metric        </span>‚îÉ<span style=\"font-weight: bold\">       DataLoader 0        </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         Test MSE          </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    0.3911325931549072     </span>‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MPNN model performance: RMSE on test set = 0.6254.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Here we create an instance of our GNN.\n",
        "# Play around with the hyperparameters!\n",
        "gnn_model = MPNN(\n",
        "    hidden_dim=64,\n",
        "    out_dim=1,\n",
        "    std=std,\n",
        "    train_data=train_dataset,\n",
        "    valid_data=valid_dataset,\n",
        "    test_data=test_dataset,\n",
        "    lr=0.001,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 60)\n",
        "\n",
        "trainer.fit(model=gnn_model)\n",
        "\n",
        "# Now run test\n",
        "results = trainer.test(ckpt_path=\"best\")\n",
        "\n",
        "# Test RMSE\n",
        "test_mse = results[0][\"Test MSE\"]\n",
        "test_rmse = test_mse ** 0.5\n",
        "print(f\"\\nMPNN model performance: RMSE on test set = {test_rmse:.4f}.\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc36f62ae76f4dc38dab14555aa22c1c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d837bdc3f6cf4ed087f81be81d2b03b3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 59/59 \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 25/25 \u001b[2m0:00:06 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m3.77it/s\u001b[0m \u001b[3mv_num: 0.000\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 59/59 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 25/25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:06 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">3.77it/s</span> <span style=\"font-style: italic\">v_num: 0.000</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d837bdc3f6cf4ed087f81be81d2b03b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff409cb008a4b95997bb5710d1dba7d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_25ce15a256fd4f5e9a7c49659161cd61",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Testing \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 8/8 \u001b[2m0:00:00 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m14.00it/s\u001b[0m  \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 8/8 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">14.00it/s</span>  \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "25ce15a256fd4f5e9a7c49659161cd61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}